{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.optimizers import RMSprop\r\n",
    "import keras_preprocessing\r\n",
    "from keras_preprocessing import image\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpimg\r\n",
    "import os\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# loading saved model for verification. \r\n",
    "# loading using two methods. One is using .h5 file and loading using file path. \r\n",
    "\r\n",
    "\r\n",
    "model_dir = r\"model\"\r\n",
    "\r\n",
    "# loading using .h5 file\r\n",
    "new_fruit_model = tf.keras.models.load_model(\r\n",
    "    model_dir,\r\n",
    "    custom_objects=None,\r\n",
    "    compile=True\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,473,475\n",
      "Trainable params: 3,473,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_fruit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0.]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_apple = r\"fruitData\\Apple\\20red applee07601.png\"\r\n",
    "\r\n",
    "img = image.load_img(single_apple, target_size = (150, 150))\r\n",
    "array = image.img_to_array(img)\r\n",
    "x = np.expand_dims(array, axis=0)\r\n",
    "\r\n",
    "vimage = np.vstack([x])\r\n",
    "new_fruit_model.predict(vimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2393 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
    "\r\n",
    "test_dir = r\"fruitSplit\\test\" #sciezka do pliku z zdjeciami do testow\r\n",
    "test_gen = test_datagen.flow_from_directory(test_dir, \r\n",
    "                                                target_size=(150, 150), # all images will be resized to 150, 150 when it is loaded\r\n",
    "                                                class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 46s 609ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "[0.010349222458899021, 0.9966568946838379]\n"
     ]
    }
   ],
   "source": [
    "result = new_fruit_model.evaluate(test_gen)\r\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('FruitRecognition-0gOXzYKb': pipenv)",
   "name": "python379jvsc74a57bd0ada95b7aa760c7ebc72eb3c8df3846e63d172e26ec59dab7d388de2df4652aa1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}